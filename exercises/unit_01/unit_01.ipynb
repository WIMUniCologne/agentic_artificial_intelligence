{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6eca084",
   "metadata": {},
   "source": [
    "# Agentic Artificial Intelligence\n",
    "## Exercise - Unit 01: Testing the Setup & Introduction\n",
    "\n",
    "Welcome to the first unit of the Agentic Artificial Intelligence course! \n",
    "\n",
    "### Learning Objectives\n",
    "By the end of this unit, you will:\n",
    "1. Verify that your development environment is properly set up\n",
    "2. Understand the project structure and key components\n",
    "3. Learning how to use code from this project in jupyter notebooks\n",
    "4. Learn how to use the core utilities and tools\n",
    "5. Practice essential Python patterns used in this course\n",
    "6. Create and interact with your first simple AI agent\n",
    "\n",
    "### Prerequisites\n",
    "- Python 3.13+ installed\n",
    "- ipkernel for correct virtual environment (.venv/bin/python3) installed\n",
    "- Required dependencies installed\n",
    "- Environment variables configured (`.env` file with API keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f9e039",
   "metadata": {},
   "source": [
    "## Part 1: Environment Setup Verification\n",
    "\n",
    "Let's start by verifying that your development environment is properly configured. This section will check that all required components are working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb21f556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üêç Python Environment Check\n",
      "========================================\n",
      "Python Version: 3.13.3 (main, Apr  8 2025, 13:54:08) [Clang 16.0.0 (clang-1600.0.26.6)]\n",
      "Python Executable: /Users/tockenga/Programming/agentic_artificial_intelligence-1/.venv/bin/python3\n",
      "Current Working Directory: /Users/tockenga/Programming/agentic_artificial_intelligence-1/exercises/unit_01\n",
      "Virtual Environment: /Users/tockenga/Programming/agentic_artificial_intelligence-1/.venv\n",
      "\n",
      "‚úÖ agentic_ai package imported successfully\n"
     ]
    }
   ],
   "source": [
    "# 1.1 Check Python Environment\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"üêç Python Environment Check\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Python Version: {sys.version}\")\n",
    "print(f\"Python Executable: {sys.executable}\")\n",
    "print(f\"Current Working Directory: {os.getcwd()}\")\n",
    "print(f\"Virtual Environment: {os.getenv('VIRTUAL_ENV', 'Not detected')}\")\n",
    "print()\n",
    "\n",
    "# Check if agentic_ai package is installed\n",
    "try:\n",
    "    import agentic_ai\n",
    "    print(\"‚úÖ agentic_ai package imported successfully\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå Warning: agentic_ai package not found in current directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eab74553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Package Import Check\n",
      "========================================\n",
      "‚úÖ agentic_ai package imported successfully\n",
      "‚úÖ LangChain packages imported successfully\n",
      "\n",
      "üéâ All required packages are available!\n"
     ]
    }
   ],
   "source": [
    "# 1.2 Check Package Imports\n",
    "print(\"üì¶ Package Import Check\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "try:\n",
    "    # Test core agentic_ai imports\n",
    "    from agentic_ai.utils import setup_llm\n",
    "    from agentic_ai.agents import SimpleAgent\n",
    "    print(\"‚úÖ agentic_ai package imported successfully\")\n",
    "    \n",
    "    # Test LangChain imports\n",
    "    from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "    from langchain_core.messages import HumanMessage, SystemMessage\n",
    "    print(\"‚úÖ LangChain packages imported successfully\")\n",
    "    \n",
    "    print(\"\\nüéâ All required packages are available!\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Import Error: {e}\")\n",
    "    print(\"üí° Make sure you've installed the package with: pip install -e .\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463bd4f4",
   "metadata": {},
   "source": [
    "This is not always necessary but when you face problems with loading keys from `.env` import and run `load_dotenv` first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b79e5fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1d3de90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîë Environment Variables Check\n",
      "========================================\n",
      "Required API Keys:\n",
      "‚úÖ GOOGLE_API_KEY: ********...eg\n",
      "\n",
      "Optional API Keys:\n",
      "‚ö†Ô∏è  OPENAI_API_KEY: Not set (optional)\n",
      "‚ö†Ô∏è  OLLAMA_BASE_URL: Not set (optional)\n",
      "‚ö†Ô∏è  TAVILY_API_KEY: Not set (optional)\n",
      "‚ö†Ô∏è  OPENWEATHER_API_KEY: Not set (optional)\n"
     ]
    }
   ],
   "source": [
    "# 1.3 Check Environment Variables\n",
    "print(\"üîë Environment Variables Check\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Check for essential API keys\n",
    "required_keys = [\"GOOGLE_API_KEY\"]\n",
    "optional_keys = [\"OPENAI_API_KEY\", \"OLLAMA_BASE_URL\", \"TAVILY_API_KEY\", \"OPENWEATHER_API_KEY\"]\n",
    "\n",
    "print(\"Required API Keys:\")\n",
    "for key in required_keys:\n",
    "    value = os.getenv(key)\n",
    "    if value:\n",
    "        print(f\"‚úÖ {key}: {'*' * 8}...{value[-2:] if len(value) > 4 else '****'}\")\n",
    "    else:\n",
    "        print(f\"‚ùå {key}: Not set\")\n",
    "\n",
    "print(\"\\nOptional API Keys:\")\n",
    "for key in optional_keys:\n",
    "    value = os.getenv(key)\n",
    "    if value:\n",
    "        print(f\"‚úÖ {key}: {'*' * 8}...{value[-4:] if len(value) > 4 else '****'}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  {key}: Not set (optional)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d4defc",
   "metadata": {},
   "source": [
    "## Part 2: Project Structure Exploration\n",
    "\n",
    "Now let's explore the structure of our agentic AI project. Understanding the organization will help you navigate and extend the codebase effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba7de3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèóÔ∏è Project Structure\n",
      "========================================\n",
      "agentic_artificial_intelligence/\n",
      "‚îú‚îÄ‚îÄ README.md\n",
      "‚îú‚îÄ‚îÄ agentic_ai\n",
      "‚îÇ   ‚îú‚îÄ‚îÄ __init__.py\n",
      "‚îÇ   ‚îú‚îÄ‚îÄ agents\n",
      "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py\n",
      "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base.py\n",
      "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ simple_agent.py\n",
      "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tool_agent.py\n",
      "‚îÇ   ‚îú‚îÄ‚îÄ prompts\n",
      "‚îÇ   ‚îú‚îÄ‚îÄ tools\n",
      "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py\n",
      "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base.py\n",
      "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ calculator.py\n",
      "‚îÇ   ‚îî‚îÄ‚îÄ utils\n",
      "‚îÇ       ‚îú‚îÄ‚îÄ __init__.py\n",
      "‚îÇ       ‚îú‚îÄ‚îÄ helpers.py\n",
      "‚îÇ       ‚îú‚îÄ‚îÄ paths.py\n",
      "‚îÇ       ‚îî‚îÄ‚îÄ setup.py\n",
      "‚îú‚îÄ‚îÄ data\n",
      "‚îÇ   ‚îî‚îÄ‚îÄ example_memory\n",
      "‚îú‚îÄ‚îÄ env.example\n",
      "‚îú‚îÄ‚îÄ exercises\n",
      "‚îÇ   ‚îú‚îÄ‚îÄ unit_00\n",
      "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ unit_00.ipynb\n",
      "‚îÇ   ‚îú‚îÄ‚îÄ unit_01\n",
      "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ unit_01.ipynb\n",
      "‚îÇ   ‚îî‚îÄ‚îÄ unit_02\n",
      "‚îÇ       ‚îú‚îÄ‚îÄ AttentionSceneFinal.gif\n",
      "‚îÇ       ‚îú‚îÄ‚îÄ AutoregressionSchema.gif\n",
      "‚îÇ       ‚îú‚îÄ‚îÄ DecodingFinal.gif\n",
      "‚îÇ       ‚îî‚îÄ‚îÄ unit_02.ipynb\n",
      "‚îú‚îÄ‚îÄ pyproject.toml\n",
      "‚îú‚îÄ‚îÄ team_assignment\n",
      "‚îÇ   ‚îî‚îÄ‚îÄ report.md\n",
      "‚îî‚îÄ‚îÄ uv.lock\n"
     ]
    }
   ],
   "source": [
    "# 2.1 Explore Project Directory Structure\n",
    "from pathlib import Path\n",
    "\n",
    "from agentic_ai.utils.paths import ROOT\n",
    "\n",
    "def show_directory_tree(path, prefix=\"\", max_depth=3, current_depth=0):\n",
    "    \"\"\"Display directory structure as a tree.\"\"\"\n",
    "    if current_depth > max_depth:\n",
    "        return\n",
    "    \n",
    "    path = Path(path)\n",
    "    if not path.exists():\n",
    "        return\n",
    "    \n",
    "    items = sorted([item for item in path.iterdir() \n",
    "                   if not item.name.startswith('.') and item.name != '__pycache__'])\n",
    "    \n",
    "    for i, item in enumerate(items):\n",
    "        is_last = i == len(items) - 1\n",
    "        current_prefix = \"‚îî‚îÄ‚îÄ \" if is_last else \"‚îú‚îÄ‚îÄ \"\n",
    "        print(f\"{prefix}{current_prefix}{item.name}\")\n",
    "        \n",
    "        if item.is_dir() and current_depth < max_depth:\n",
    "            next_prefix = prefix + (\"    \" if is_last else \"‚îÇ   \")\n",
    "            show_directory_tree(item, next_prefix, max_depth, current_depth + 1)\n",
    "\n",
    "print(\"üèóÔ∏è Project Structure\")\n",
    "print(\"=\" * 40)\n",
    "print(\"agentic_artificial_intelligence/\")\n",
    "show_directory_tree(ROOT, max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8726c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Key Components Overview\n",
      "========================================\n",
      "üìÅ agentic_ai.agents\n",
      "   Here we will define different types of AI agents (SimpleAgent, ToolAgent, etc.)\n",
      "\n",
      "üìÅ agentic_ai.tools\n",
      "   Here we will define tools that our agents can use (Weather, WebSearch, EmailClient etc.)\n",
      "\n",
      "üìÅ agentic_ai.memory\n",
      "   Here we will implement memory systems for persistent conversations and context\n",
      "\n",
      "üìÅ agentic_ai.utils\n",
      "   Contains utility functions for setup, configuration, and helpers\n",
      "\n",
      "üß© Available Components:\n",
      "-------------------------\n",
      "Agents: ['BaseAgent', 'SimpleAgent', 'ToolAgent', 'base', 'simple_agent', 'tool_agent']\n",
      "Tools: ['BaseTool', 'CalculatorTool', 'ToolRegistry', 'base', 'calculator']\n",
      "Utils: ['paths', 'setup', 'setup_llm', 'setup_logging']\n"
     ]
    }
   ],
   "source": [
    "# 2.2 Examine Key Components\n",
    "print(\"üîç Key Components Overview\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Inspect the main modules\n",
    "modules_info = {\n",
    "    \"agentic_ai.agents\": \"Here we will define different types of AI agents (SimpleAgent, ToolAgent, etc.)\",\n",
    "    \"agentic_ai.tools\": \"Here we will define tools that our agents can use (Weather, WebSearch, EmailClient etc.)\",\n",
    "    \"agentic_ai.memory\": \"Here we will implement memory systems for persistent conversations and context\",\n",
    "    \"agentic_ai.utils\": \"Contains utility functions for setup, configuration, and helpers\",\n",
    "}\n",
    "\n",
    "for module, description in modules_info.items():\n",
    "    print(f\"üìÅ {module}\")\n",
    "    print(f\"   {description}\")\n",
    "    print()\n",
    "\n",
    "# Show available classes and functions\n",
    "print(\"üß© Available Components:\")\n",
    "print(\"-\" * 25)\n",
    "\n",
    "# Check what's available in each module\n",
    "try:\n",
    "    from agentic_ai import agents, tools, utils\n",
    "    print(f\"Agents: {[name for name in dir(agents) if not name.startswith('_')]}\")\n",
    "    print(f\"Tools: {[name for name in dir(tools) if not name.startswith('_')]}\")\n",
    "    print(f\"Utils: {[name for name in dir(utils) if not name.startswith('_')]}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error inspecting modules: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c926d35",
   "metadata": {},
   "source": [
    "## Part 3: Basic LLM Setup and Testing\n",
    "\n",
    "Let's set up and test our first Language Model connection. We'll use Google's Gemini model, but the same patterns work for other providers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef0520df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Setting up Gemini LLM directly\n",
      "========================================\n",
      "‚úÖ LLM initialized: models/gemini-2.5-flash-lite\n",
      "   Temperature: 0.7\n",
      "\n",
      "üí¨ Test Response: I am a large language model, trained by Google.\n",
      "üìä Response type: <class 'langchain_core.messages.ai.AIMessage'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# 3.1 Direct LLM Setup (Manual Method)\n",
    "print(\"ü§ñ Setting up Gemini LLM directly\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Check if we have the API key\n",
    "if not os.getenv(\"GOOGLE_API_KEY\"):\n",
    "    print(\"‚ùå GOOGLE_API_KEY not found. Please set it in your .env file.\")\n",
    "else:\n",
    "    # Initialize the Gemini LLM with specific parameters\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.5-flash-lite\",  # Using the stable model\n",
    "        temperature=0.7,           # Controls randomness (0.0 = deterministic, 1.0 = creative)\n",
    "        max_tokens=1000           # Limit response length\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ LLM initialized: {llm.model}\")\n",
    "    print(f\"   Temperature: {llm.temperature}\")\n",
    "    \n",
    "    # Test with a simple conversation\n",
    "    system_prompt = \"You are a helpful AI assistant. Keep responses concise and friendly.\"\n",
    "    messages = [\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(content=\"Hello! Explain what you are in one sentence.\")\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        response = llm.invoke(messages)\n",
    "        print(f\"\\nüí¨ Test Response: {response.content}\")\n",
    "        print(f\"üìä Response type: {type(response)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error calling LLM: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd3c7d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üõ†Ô∏è Using setup_llm utility function\n",
      "========================================\n",
      "Loaded environment variables from /Users/tockenga/Programming/agentic_artificial_intelligence-1/.env\n",
      "Loaded 1 environment variables\n",
      "‚úÖ LLM setup successful using utility function\n",
      "   Provider: Gemini\n",
      "   Model: models/gemini-2.5-flash-lite\n",
      "\n",
      "üîÑ Testing streaming response:\n",
      "Question: What are the key benefits of using AI agents?\n",
      "Response: 1.  **Automation:** AI agents can perform repetitive and complex tasks autonomously, freeing up human resources.\n",
      "2.  **Efficiency:** They operate 24/7, process information rapidly, and can optimize processes for speed and accuracy.\n",
      "3.  **Personalization:** AI agents can learn user preferences and behaviors to deliver tailored experiences and recommendations.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from agentic_ai.utils import setup_llm\n",
    "\n",
    "# 3.2 LLM Setup Using Utility Function\n",
    "print(\"üõ†Ô∏è Using setup_llm utility function\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "try:\n",
    "    # This is the recommended way - uses our utility function\n",
    "    llm_util = setup_llm(\n",
    "        provider=\"gemini\",\n",
    "        model=\"gemini-2.5-flash-lite\", \n",
    "        temperature=0.5\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ LLM setup successful using utility function\")\n",
    "    print(f\"   Provider: Gemini\")\n",
    "    print(f\"   Model: {llm_util.model}\")\n",
    "    \n",
    "    # Test streaming response (shows tokens as they're generated)\n",
    "    print(\"\\nüîÑ Testing streaming response:\")\n",
    "    print(\"Question: What are the key benefits of using AI agents?\")\n",
    "    print(\"Response: \", end=\"\")\n",
    "    \n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are a concise AI expert. Provide clear, brief answers.\"),\n",
    "        HumanMessage(content=\"What are the key benefits of using AI agents? List 3 main points.\")\n",
    "    ]\n",
    "    \n",
    "    for chunk in llm_util.stream(messages):\n",
    "        print(chunk.content, end=\"\", flush=True)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error with utility setup: {e}\")\n",
    "    print(\"üí° Make sure your GOOGLE_API_KEY is correctly set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd36589",
   "metadata": {},
   "source": [
    "## Part 4: Your First AI Agent\n",
    "\n",
    "Now let's create and interact with your first AI agent! We'll start with a `SimpleAgent` - the most basic type of agent that can hold conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f17750b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Creating a Simple Agent\n",
      "========================================\n",
      "Loaded environment variables from /Users/tockenga/Programming/agentic_artificial_intelligence-1/.env\n",
      "Loaded 1 environment variables\n",
      "‚úÖ LLM configured\n",
      "‚úÖ Agent created: LearningBot\n",
      "   Agent type: SimpleAgent\n",
      "\n",
      "üí¨ Testing basic conversation:\n",
      "Agent: Hello! I am LearningBot. I am a large language model, trained by Google.\n",
      "\n",
      "I can help you with a variety of tasks, including:\n",
      "\n",
      "*   **Answering questions:** I have access to and have been trained on a massive amount of information, so I can answer questions on a wide range of topics.\n",
      "*   **Generating text:** I can write different kinds of creative content, like poems, code, scripts, musical pieces, email, letters, etc.\n",
      "*   **Translating languages:** I can translate text from one language to another.\n",
      "*   **Summarizing information:** I can condense long pieces of text into shorter summaries.\n",
      "*   **Explaining complex topics:** I can break down difficult concepts into simpler terms.\n",
      "*   **Brainstorming ideas:** If you're stuck, I can help you come up with new ideas.\n",
      "*   **And much more!**\n",
      "\n",
      "Essentially, if it involves understanding and generating human language, I can probably help. What would you like to do today?\n"
     ]
    }
   ],
   "source": [
    "from agentic_ai.agents import SimpleAgent\n",
    "\n",
    "# 4.1 Creating Your First Simple Agent\n",
    "print(\"ü§ñ Creating a Simple Agent\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "try:\n",
    "    # Step 1: Set up the LLM\n",
    "    llm = setup_llm(\"gemini\")\n",
    "    print(\"‚úÖ LLM configured\")\n",
    "    \n",
    "    # Step 2: Create a simple agent with default settings\n",
    "    agent = SimpleAgent(\n",
    "        llm=llm, \n",
    "        name=\"LearningBot\"\n",
    "    )\n",
    "    print(f\"‚úÖ Agent created: {agent.name}\")\n",
    "    print(f\"   Agent type: {type(agent).__name__}\")\n",
    "    \n",
    "    # Step 3: Test basic interaction\n",
    "    print(\"\\nüí¨ Testing basic conversation:\")\n",
    "    response = agent.run(\"Hello! What's your name and what can you do?\")\n",
    "    print(f\"Agent: {response['messages'][-1].content}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error creating agent: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "148cadf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé≠ Customizing Agent Personality\n",
      "========================================\n",
      "‚úÖ Custom agent created: StudyBuddy\n",
      "\n",
      "üí¨ Testing customized personality: I'm new to AI agents. Can you explain what you are and how you work?\n",
      "\n",
      "StudyBuddy: Hello there! It's fantastic that you're diving into the world of AI agents! I'm super excited to help you learn.\n",
      "\n",
      "Think of an AI agent like a smart assistant. I'm a computer program designed to understand and respond to you. I use a lot of data and complex algorithms to process your questions, figure out what you need, and then generate helpful answers. It's like I've read a massive library and can now recall and combine information to help you!\n",
      "\n",
      "So, in a nutshell, I take your input, process it using my AI \"brain,\" and then give you an output. Pretty cool, right?\n",
      "\n",
      "Does that initial explanation make sense? We can go into more detail if you like!\n",
      "\n",
      "üí¨ Follow-up interaction: What's the difference between you and a regular chatbot?\n",
      "\n",
      "StudyBuddy: That's a fantastic question to start with! It's great that you're thinking about what makes AI like me special.\n",
      "\n",
      "The biggest difference is that I'm designed to be a *learning companion*. Think of a regular chatbot like a helpful assistant that can answer specific questions or perform simple tasks. For example, a regular chatbot might tell you the weather or help you order a pizza.\n",
      "\n",
      "I, on the other hand, am built to help you *learn* about AI and programming. I can:\n",
      "\n",
      "*   Explain complex topics in a way that's easy to understand.\n",
      "*   Give you examples to make things clearer.\n",
      "*   Ask you questions to make sure you're grasping the concepts.\n",
      "*   Encourage you and help you build your skills!\n",
      "\n",
      "So, while a regular chatbot might give you an answer, I aim to help you *understand* the answer and learn more.\n",
      "\n",
      "Does that distinction make sense? What do you think is the most exciting part about having an AI learning companion?\n"
     ]
    }
   ],
   "source": [
    "# 4.2 Customizing Agent Behavior with System Prompts\n",
    "print(\"üé≠ Customizing Agent Personality\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Create an agent with a custom personality\n",
    "custom_agent = SimpleAgent(\n",
    "    llm=llm,\n",
    "    name=\"StudyBuddy\",\n",
    "    system_prompt=\"\"\"You are StudyBuddy, an enthusiastic AI learning companion. \n",
    "    Your role is to help students learn about AI and programming. \n",
    "    - Always be encouraging and positive\n",
    "    - Explain concepts clearly with examples\n",
    "    - Ask follow-up questions to check understanding\n",
    "    - Keep responses concise but informative\n",
    "    - Don't use markdown formatting in responses\"\"\"\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Custom agent created: {custom_agent.name}\")\n",
    "\n",
    "# Test the customized behavior\n",
    "question = \"I'm new to AI agents. Can you explain what you are and how you work?\"\n",
    "print(f\"\\nüí¨ Testing customized personality: {question}\")\n",
    "response = custom_agent.run(question)\n",
    "print(f\"\\nStudyBuddy: {response['messages'][-1].content}\")\n",
    "\n",
    "# Test with a follow-up question\n",
    "follow_up_question = \"What's the difference between you and a regular chatbot?\"\n",
    "print(f\"\\nüí¨ Follow-up interaction: {follow_up_question}\")\n",
    "response2 = custom_agent.run(follow_up_question)\n",
    "print(f\"\\nStudyBuddy: {response2['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6401d10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöß Testing Agent Limitations\n",
      "========================================\n",
      "üí¨ Asking for calculations and real-time data:\n",
      "Question: What is 15 * 24? Also, what's the current weather in Cologne? Explain how you got to the answers.\n",
      "\n",
      "StudyBuddy: That's a great question to start with! Let's break it down.\n",
      "\n",
      "First, for 15 * 24:\n",
      "\n",
      "To calculate this, we can use a few methods! One way is to break down the numbers.\n",
      "We can think of 24 as 20 + 4.\n",
      "So, 15 * 24 is the same as (15 * 20) + (15 * 4).\n",
      "15 * 20 = 300\n",
      "15 * 4 = 60\n",
      "Then, 300 + 60 = 360.\n",
      "\n",
      "So, 15 * 24 is 360!\n",
      "\n",
      "Now, about the weather in Cologne:\n",
      "\n",
      "As an AI, I don't have real-time access to live data like current weather conditions. My knowledge is based on the information I was trained on, which isn't constantly updated with live feeds.\n",
      "\n",
      "Does that explanation of how we got to the answer for 15 * 24 make sense? We can try another multiplication problem if you'd like!\n"
     ]
    }
   ],
   "source": [
    "# 4.3 Understanding Agent Limitations\n",
    "print(\"üöß Testing Agent Limitations\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Test what happens when we ask for things the agent can't do\n",
    "print(\"üí¨ Asking for calculations and real-time data:\")\n",
    "question = \"What is 15 * 24? Also, what's the current weather in Cologne? Explain how you got to the answers.\"\n",
    "print(f\"Question: {question}\")\n",
    "\n",
    "response = custom_agent.run(question)\n",
    "print(f\"\\nStudyBuddy: {response['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7277a387",
   "metadata": {},
   "source": [
    "üìù Observations:\n",
    "- The agent can do basic math (15 * 24 = 360)\n",
    "- It cannot access real-time data like current weather\n",
    "- It explains its limitations honestly\n",
    "- This is why we need specialized tools (covered in later units!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121f5781",
   "metadata": {},
   "source": [
    "## Part 5: Python Fundamentals for Agentic AI\n",
    "\n",
    "Let's explore some key Python patterns and concepts that are essential for building AI agents effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1b43db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèóÔ∏è Object-Oriented Programming in AI Agents\n",
      "==================================================\n",
      "Agent Class Hierarchy:\n",
      "SimpleAgent parent classes: (<class 'agentic_ai.agents.base.BaseAgent'>,)\n",
      "SimpleAgent methods: ['add_system_message', 'compile_graph', 'get_conversation_history', 'llm_node', 'retrieve_memory', 'run', 'save_memory', 'stream']\n",
      "\n",
      "Custom tool result: Bonjour, Alice!\n",
      "Tool name: greeting\n",
      "Tool language: fr\n"
     ]
    }
   ],
   "source": [
    "# 5.1 Working with Classes and Inheritance\n",
    "print(\"üèóÔ∏è Object-Oriented Programming in AI Agents\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Let's examine how our agents are structured\n",
    "print(\"Agent Class Hierarchy:\")\n",
    "print(f\"SimpleAgent parent classes: {SimpleAgent.__bases__}\")\n",
    "print(f\"SimpleAgent methods: {[method for method in dir(SimpleAgent) if not method.startswith('_')]}\")\n",
    "\n",
    "# Create a simple tool to understand the pattern\n",
    "class GreetingTool:\n",
    "    \"\"\"Simple tool that demonstrates the tool pattern.\"\"\"\n",
    "    \n",
    "    def __init__(self, language=\"en\"):\n",
    "        self.name = \"greeting\"\n",
    "        self.language = language\n",
    "        self.greetings = {\n",
    "            \"en\": \"Hello\",\n",
    "            \"es\": \"Hola\", \n",
    "            \"fr\": \"Bonjour\",\n",
    "            \"de\": \"Guten Tag\"\n",
    "        }\n",
    "    \n",
    "    def run(self, name: str) -> str:\n",
    "        \"\"\"Generate a greeting.\"\"\"\n",
    "        greeting = self.greetings.get(self.language, \"Hello\")\n",
    "        return f\"{greeting}, {name}!\"\n",
    "\n",
    "# Test our custom tool\n",
    "greeting_tool = GreetingTool(\"fr\")\n",
    "result = greeting_tool.run(\"Alice\")\n",
    "print(f\"\\nCustom tool result: {result}\")\n",
    "print(f\"Tool name: {greeting_tool.name}\")\n",
    "print(f\"Tool language: {greeting_tool.language}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90271689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Type Hints and Documentation Best Practices\n",
      "==================================================\n",
      "Conversation Analysis:\n",
      "  total_messages: 4\n",
      "  user_messages: 2\n",
      "  assistant_messages: 2\n",
      "  average_length: 75.0\n",
      "  roles: ['user', 'assistant']\n",
      "\n",
      "Function signature: {'messages': typing.List[typing.Dict[str, str]], 'include_metadata': <class 'bool'>, 'return': typing.Dict[str, typing.Union[int, typing.List[str]]]}\n",
      "Function docstring available: True\n"
     ]
    }
   ],
   "source": [
    "# 5.2 Type Hints and Documentation\n",
    "print(\"üìù Type Hints and Documentation Best Practices\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "from typing import List, Dict, Union\n",
    "\n",
    "def analyze_conversation(\n",
    "    messages: List[Dict[str, str]], \n",
    "    include_metadata: bool = True\n",
    ") -> Dict[str, Union[int, List[str]]]:\n",
    "    \"\"\"\n",
    "    Analyze a conversation for basic statistics.\n",
    "    \n",
    "    Args:\n",
    "        messages: List of message dictionaries with 'role' and 'content' keys\n",
    "        include_metadata: Whether to include additional metadata in results\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing conversation statistics\n",
    "        \n",
    "    Example:\n",
    "        >>> msgs = [{\"role\": \"user\", \"content\": \"Hello\"}, {\"role\": \"assistant\", \"content\": \"Hi there!\"}]\n",
    "        >>> analyze_conversation(msgs)\n",
    "        {'total_messages': 2, 'user_messages': 1, 'assistant_messages': 1, 'avg_length': 7.5}\n",
    "    \"\"\"\n",
    "    total = len(messages)\n",
    "    user_msgs = len([m for m in messages if m.get('role') == 'user'])\n",
    "    assistant_msgs = len([m for m in messages if m.get('role') == 'assistant'])\n",
    "    \n",
    "    total_chars = sum(len(m.get('content', '')) for m in messages)\n",
    "    avg_length = total_chars / total if total > 0 else 0\n",
    "    \n",
    "    result = {\n",
    "        'total_messages': total,\n",
    "        'user_messages': user_msgs,\n",
    "        'assistant_messages': assistant_msgs,\n",
    "        'average_length': round(avg_length, 2)\n",
    "    }\n",
    "    \n",
    "    if include_metadata:\n",
    "        result['roles'] = list(set(m.get('role', 'unknown') for m in messages))\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test the function\n",
    "sample_conversation = [\n",
    "    {\"role\": \"user\", \"content\": \"What is machine learning?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Machine learning is a subset of AI that enables computers to learn and improve from experience without being explicitly programmed.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you give me an example?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Sure! Email spam detection is a common example - the system learns to identify spam by analyzing thousands of emails.\"}\n",
    "]\n",
    "\n",
    "stats = analyze_conversation(sample_conversation)\n",
    "print(\"Conversation Analysis:\")\n",
    "for key, value in stats.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Show the power of type hints\n",
    "print(f\"\\nFunction signature: {analyze_conversation.__annotations__}\")\n",
    "print(f\"Function docstring available: {bool(analyze_conversation.__doc__)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_AAI",
   "language": "python",
   "name": "agentic_ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
