{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6eca084",
   "metadata": {},
   "source": [
    "# Agentic Artificial Intelligence\n",
    "## Exercise - Unit 01: Testing the Setup & Introduction\n",
    "\n",
    "Welcome to the first unit of the Agentic Artificial Intelligence course! \n",
    "\n",
    "### Learning Objectives\n",
    "By the end of this unit, you will:\n",
    "1. Verify that your development environment is properly set up\n",
    "2. Understand the project structure and key components\n",
    "3. Learning how to use code from this project in jupyter notebooks\n",
    "4. Learn how to use the core utilities and tools\n",
    "5. Practice essential Python patterns used in this course\n",
    "6. Create and interact with your first simple AI agent\n",
    "\n",
    "### Prerequisites\n",
    "- Python 3.13+ installed\n",
    "- ipkernel for correct virtual environment (.venv/bin/python3) installed\n",
    "- Required dependencies installed\n",
    "- Environment variables configured (`.env` file with API keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f9e039",
   "metadata": {},
   "source": [
    "## Part 1: Environment Setup Verification\n",
    "\n",
    "Let's start by verifying that your development environment is properly configured. This section will check that all required components are working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb21f556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🐍 Python Environment Check\n",
      "========================================\n",
      "Python Version: 3.13.3 (main, Apr  8 2025, 13:54:08) [Clang 16.0.0 (clang-1600.0.26.6)]\n",
      "Python Executable: /Users/tockenga/Programming/agentic_artificial_intelligence-1/.venv/bin/python3\n",
      "Current Working Directory: /Users/tockenga/Programming/agentic_artificial_intelligence-1/exercises/unit_01\n",
      "Virtual Environment: /Users/tockenga/Programming/agentic_artificial_intelligence-1/.venv\n",
      "\n",
      "✅ agentic_ai package imported successfully\n"
     ]
    }
   ],
   "source": [
    "# 1.1 Check Python Environment\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"🐍 Python Environment Check\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Python Version: {sys.version}\")\n",
    "print(f\"Python Executable: {sys.executable}\")\n",
    "print(f\"Current Working Directory: {os.getcwd()}\")\n",
    "print(f\"Virtual Environment: {os.getenv('VIRTUAL_ENV', 'Not detected')}\")\n",
    "print()\n",
    "\n",
    "# Check if agentic_ai package is installed\n",
    "try:\n",
    "    import agentic_ai\n",
    "    print(\"✅ agentic_ai package imported successfully\")\n",
    "except ImportError:\n",
    "    print(\"❌ Warning: agentic_ai package not found in current directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eab74553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Package Import Check\n",
      "========================================\n",
      "✅ agentic_ai package imported successfully\n",
      "✅ LangChain packages imported successfully\n",
      "\n",
      "🎉 All required packages are available!\n"
     ]
    }
   ],
   "source": [
    "# 1.2 Check Package Imports\n",
    "print(\"📦 Package Import Check\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "try:\n",
    "    # Test core agentic_ai imports\n",
    "    from agentic_ai.utils import setup_llm\n",
    "    from agentic_ai.agents import SimpleAgent\n",
    "    print(\"✅ agentic_ai package imported successfully\")\n",
    "    \n",
    "    # Test LangChain imports\n",
    "    from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "    from langchain_core.messages import HumanMessage, SystemMessage\n",
    "    print(\"✅ LangChain packages imported successfully\")\n",
    "    \n",
    "    print(\"\\n🎉 All required packages are available!\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"❌ Import Error: {e}\")\n",
    "    print(\"💡 Make sure you've installed the package with: pip install -e .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1d3de90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔑 Environment Variables Check\n",
      "========================================\n",
      "Required API Keys:\n",
      "✅ GOOGLE_API_KEY: ********...eg\n",
      "\n",
      "Optional API Keys:\n",
      "⚠️  OPENAI_API_KEY: Not set (optional)\n",
      "⚠️  OLLAMA_BASE_URL: Not set (optional)\n",
      "⚠️  TAVILY_API_KEY: Not set (optional)\n",
      "⚠️  OPENWEATHER_API_KEY: Not set (optional)\n"
     ]
    }
   ],
   "source": [
    "# 1.3 Check Environment Variables\n",
    "print(\"🔑 Environment Variables Check\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Check for essential API keys\n",
    "required_keys = [\"GOOGLE_API_KEY\"]\n",
    "optional_keys = [\"OPENAI_API_KEY\", \"OLLAMA_BASE_URL\", \"TAVILY_API_KEY\", \"OPENWEATHER_API_KEY\"]\n",
    "\n",
    "print(\"Required API Keys:\")\n",
    "for key in required_keys:\n",
    "    value = os.getenv(key)\n",
    "    if value:\n",
    "        print(f\"✅ {key}: {'*' * 8}...{value[-2:] if len(value) > 4 else '****'}\")\n",
    "    else:\n",
    "        print(f\"❌ {key}: Not set\")\n",
    "\n",
    "print(\"\\nOptional API Keys:\")\n",
    "for key in optional_keys:\n",
    "    value = os.getenv(key)\n",
    "    if value:\n",
    "        print(f\"✅ {key}: {'*' * 8}...{value[-4:] if len(value) > 4 else '****'}\")\n",
    "    else:\n",
    "        print(f\"⚠️  {key}: Not set (optional)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d4defc",
   "metadata": {},
   "source": [
    "## Part 2: Project Structure Exploration\n",
    "\n",
    "Now let's explore the structure of our agentic AI project. Understanding the organization will help you navigate and extend the codebase effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba7de3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏗️ Project Structure\n",
      "========================================\n",
      "agentic_artificial_intelligence/\n",
      "├── README.md\n",
      "├── agentic_ai\n",
      "│   ├── __init__.py\n",
      "│   ├── agents\n",
      "│   │   ├── __init__.py\n",
      "│   │   ├── base.py\n",
      "│   │   ├── simple_agent.py\n",
      "│   │   └── tool_agent.py\n",
      "│   ├── prompts\n",
      "│   ├── tools\n",
      "│   │   ├── __init__.py\n",
      "│   │   ├── base.py\n",
      "│   │   └── calculator.py\n",
      "│   └── utils\n",
      "│       ├── __init__.py\n",
      "│       ├── paths.py\n",
      "│       └── setup.py\n",
      "├── agentic_ai.egg-info\n",
      "│   ├── PKG-INFO\n",
      "│   ├── SOURCES.txt\n",
      "│   ├── dependency_links.txt\n",
      "│   ├── entry_points.txt\n",
      "│   ├── requires.txt\n",
      "│   └── top_level.txt\n",
      "├── data\n",
      "│   └── example_memory\n",
      "├── env.example\n",
      "├── exercises\n",
      "│   ├── unit_00\n",
      "│   │   └── unit_00.ipynb\n",
      "│   └── unit_01\n",
      "│       └── unit_01.ipynb\n",
      "├── pyproject.toml\n",
      "└── uv.lock\n"
     ]
    }
   ],
   "source": [
    "# 2.1 Explore Project Directory Structure\n",
    "from pathlib import Path\n",
    "\n",
    "from agentic_ai.utils.paths import ROOT\n",
    "\n",
    "def show_directory_tree(path, prefix=\"\", max_depth=3, current_depth=0):\n",
    "    \"\"\"Display directory structure as a tree.\"\"\"\n",
    "    if current_depth > max_depth:\n",
    "        return\n",
    "    \n",
    "    path = Path(path)\n",
    "    if not path.exists():\n",
    "        return\n",
    "    \n",
    "    items = sorted([item for item in path.iterdir() \n",
    "                   if not item.name.startswith('.') and item.name != '__pycache__'])\n",
    "    \n",
    "    for i, item in enumerate(items):\n",
    "        is_last = i == len(items) - 1\n",
    "        current_prefix = \"└── \" if is_last else \"├── \"\n",
    "        print(f\"{prefix}{current_prefix}{item.name}\")\n",
    "        \n",
    "        if item.is_dir() and current_depth < max_depth:\n",
    "            next_prefix = prefix + (\"    \" if is_last else \"│   \")\n",
    "            show_directory_tree(item, next_prefix, max_depth, current_depth + 1)\n",
    "\n",
    "print(\"🏗️ Project Structure\")\n",
    "print(\"=\" * 40)\n",
    "print(\"agentic_artificial_intelligence/\")\n",
    "show_directory_tree(ROOT, max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8726c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Examine Key Components\n",
    "print(\"🔍 Key Components Overview\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Inspect the main modules\n",
    "modules_info = {\n",
    "    \"agentic_ai.agents\": \"Here we will define different types of AI agents (SimpleAgent, ToolAgent, etc.)\",\n",
    "    \"agentic_ai.tools\": \"Here we will define tools that our agents can use (Weather, WebSearch, EmailClient etc.)\",\n",
    "    \"agentic_ai.memory\": \"Here we will implement memory systems for persistent conversations and context\",\n",
    "    \"agentic_ai.utils\": \"Contains utility functions for setup, configuration, and helpers\",\n",
    "    \"agentic_ai.llm_models\": \"Here we will implement LLM client implementations and model configurations\"\n",
    "}\n",
    "\n",
    "for module, description in modules_info.items():\n",
    "    print(f\"📁 {module}\")\n",
    "    print(f\"   {description}\")\n",
    "    print()\n",
    "\n",
    "# Show available classes and functions\n",
    "print(\"🧩 Available Components:\")\n",
    "print(\"-\" * 25)\n",
    "\n",
    "# Check what's available in each module\n",
    "try:\n",
    "    from agentic_ai import agents, tools, utils\n",
    "    print(f\"Agents: {[name for name in dir(agents) if not name.startswith('_')]}\")\n",
    "    print(f\"Tools: {[name for name in dir(tools) if not name.startswith('_')]}\")\n",
    "    print(f\"Utils: {[name for name in dir(utils) if not name.startswith('_')]}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error inspecting modules: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c926d35",
   "metadata": {},
   "source": [
    "## Part 3: Basic LLM Setup and Testing\n",
    "\n",
    "Let's set up and test our first Language Model connection. We'll use Google's Gemini model, but the same patterns work for other providers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0520df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Direct LLM Setup (Manual Method)\n",
    "print(\"🤖 Setting up Gemini LLM directly\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Check if we have the API key\n",
    "if not os.getenv(\"GOOGLE_API_KEY\"):\n",
    "    print(\"❌ GOOGLE_API_KEY not found. Please set it in your .env file.\")\n",
    "else:\n",
    "    # Initialize the Gemini LLM with specific parameters\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.5-flash\",  # Using the stable model\n",
    "        temperature=0.7,           # Controls randomness (0.0 = deterministic, 1.0 = creative)\n",
    "        max_tokens=1000           # Limit response length\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ LLM initialized: {llm.model}\")\n",
    "    print(f\"   Temperature: {llm.temperature}\")\n",
    "    \n",
    "    # Test with a simple conversation\n",
    "    system_prompt = \"You are a helpful AI assistant. Keep responses concise and friendly.\"\n",
    "    messages = [\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(content=\"Hello! Explain what you are in one sentence.\")\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        response = llm.invoke(messages)\n",
    "        print(f\"\\n💬 Test Response: {response.content}\")\n",
    "        print(f\"📊 Response type: {type(response)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error calling LLM: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3c7d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 LLM Setup Using Utility Function (Recommended Method)\n",
    "print(\"🛠️ Using setup_llm utility function\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "try:\n",
    "    # This is the recommended way - uses our utility function\n",
    "    llm_util = setup_llm(\n",
    "        provider=\"gemini\",\n",
    "        model=\"gemini-2.5-flash\", \n",
    "        temperature=0.5\n",
    "    )\n",
    "    \n",
    "    print(\"✅ LLM setup successful using utility function\")\n",
    "    print(f\"   Provider: Gemini\")\n",
    "    print(f\"   Model: {llm_util.model}\")\n",
    "    \n",
    "    # Test streaming response (shows tokens as they're generated)\n",
    "    print(\"\\n🔄 Testing streaming response:\")\n",
    "    print(\"Question: What are the key benefits of using AI agents?\")\n",
    "    print(\"Response: \", end=\"\")\n",
    "    \n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are a concise AI expert. Provide clear, brief answers.\"),\n",
    "        HumanMessage(content=\"What are the key benefits of using AI agents? List 3 main points.\")\n",
    "    ]\n",
    "    \n",
    "    for chunk in llm_util.stream(messages):\n",
    "        print(chunk.content, end=\"\", flush=True)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error with utility setup: {e}\")\n",
    "    print(\"💡 Make sure your GOOGLE_API_KEY is correctly set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd36589",
   "metadata": {},
   "source": [
    "## Part 4: Your First AI Agent\n",
    "\n",
    "Now let's create and interact with your first AI agent! We'll start with a `SimpleAgent` - the most basic type of agent that can hold conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17750b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Creating Your First Simple Agent\n",
    "print(\"🤖 Creating a Simple Agent\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "try:\n",
    "    # Step 1: Set up the LLM\n",
    "    llm = setup_llm(\"gemini\")\n",
    "    print(\"✅ LLM configured\")\n",
    "    \n",
    "    # Step 2: Create a simple agent with default settings\n",
    "    agent = SimpleAgent(\n",
    "        llm=llm, \n",
    "        name=\"LearningBot\"\n",
    "    )\n",
    "    print(f\"✅ Agent created: {agent.name}\")\n",
    "    print(f\"   Agent type: {type(agent).__name__}\")\n",
    "    \n",
    "    # Step 3: Test basic interaction\n",
    "    print(\"\\n💬 Testing basic conversation:\")\n",
    "    response = agent.run(\"Hello! What's your name and what can you do?\")\n",
    "    print(f\"Agent: {response}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error creating agent: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148cadf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 Customizing Agent Behavior with System Prompts\n",
    "print(\"🎭 Customizing Agent Personality\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Create an agent with a custom personality\n",
    "custom_agent = SimpleAgent(\n",
    "    llm=llm,\n",
    "    name=\"StudyBuddy\",\n",
    "    system_prompt=\"\"\"You are StudyBuddy, an enthusiastic AI learning companion. \n",
    "    Your role is to help students learn about AI and programming. \n",
    "    - Always be encouraging and positive\n",
    "    - Explain concepts clearly with examples\n",
    "    - Ask follow-up questions to check understanding\n",
    "    - Keep responses concise but informative\n",
    "    - Don't use markdown formatting in responses\"\"\"\n",
    ")\n",
    "\n",
    "print(f\"✅ Custom agent created: {custom_agent.name}\")\n",
    "\n",
    "# Test the customized behavior\n",
    "question = \"I'm new to AI agents. Can you explain what you are and how you work?\"\n",
    "print(f\"\\n💬 Testing customized personality: {question}\")\n",
    "response = custom_agent.run(question)\n",
    "print(f\"\\nStudyBuddy: {response}\")\n",
    "\n",
    "# Test with a follow-up question\n",
    "follow_up_question = \"What's the difference between you and a regular chatbot?\"\n",
    "print(f\"\\n💬 Follow-up interaction: {follow_up_question}\")\n",
    "response2 = custom_agent.run(follow_up_question)\n",
    "print(f\"\\nStudyBuddy: {response2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6401d10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 Understanding Agent Limitations\n",
    "print(\"🚧 Testing Agent Limitations\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Test what happens when we ask for things the agent can't do\n",
    "print(\"💬 Asking for calculations and real-time data:\")\n",
    "question = \"What is 15 * 24? Also, what's the current weather in Cologne? Explain how you got to the answers.\"\n",
    "print(f\"Question: {question}\")\n",
    "\n",
    "response = custom_agent.run(question)\n",
    "print(f\"\\nStudyBuddy: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7277a387",
   "metadata": {},
   "source": [
    "📝 Observations:\n",
    "- The agent can do basic math (15 * 24 = 360)\n",
    "- It cannot access real-time data like current weather\n",
    "- It explains its limitations honestly\n",
    "- This is why we need specialized tools (covered in later units!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121f5781",
   "metadata": {},
   "source": [
    "## Part 5: Python Fundamentals for Agentic AI\n",
    "\n",
    "Let's explore some key Python patterns and concepts that are essential for building AI agents effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b43db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Working with Classes and Inheritance\n",
    "print(\"🏗️ Object-Oriented Programming in AI Agents\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Let's examine how our agents are structured\n",
    "print(\"Agent Class Hierarchy:\")\n",
    "print(f\"SimpleAgent parent classes: {SimpleAgent.__bases__}\")\n",
    "print(f\"SimpleAgent methods: {[method for method in dir(SimpleAgent) if not method.startswith('_')]}\")\n",
    "\n",
    "# Create a simple tool to understand the pattern\n",
    "class GreetingTool:\n",
    "    \"\"\"Simple tool that demonstrates the tool pattern.\"\"\"\n",
    "    \n",
    "    def __init__(self, language=\"en\"):\n",
    "        self.name = \"greeting\"\n",
    "        self.language = language\n",
    "        self.greetings = {\n",
    "            \"en\": \"Hello\",\n",
    "            \"es\": \"Hola\", \n",
    "            \"fr\": \"Bonjour\",\n",
    "            \"de\": \"Guten Tag\"\n",
    "        }\n",
    "    \n",
    "    def run(self, name: str) -> str:\n",
    "        \"\"\"Generate a greeting.\"\"\"\n",
    "        greeting = self.greetings.get(self.language, \"Hello\")\n",
    "        return f\"{greeting}, {name}!\"\n",
    "\n",
    "# Test our custom tool\n",
    "greeting_tool = GreetingTool(\"es\")\n",
    "result = greeting_tool.run(\"Alice\")\n",
    "print(f\"\\nCustom tool result: {result}\")\n",
    "print(f\"Tool name: {greeting_tool.name}\")\n",
    "print(f\"Tool language: {greeting_tool.language}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90271689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2 Type Hints and Documentation\n",
    "print(\"📝 Type Hints and Documentation Best Practices\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "from typing import List, Dict, Union\n",
    "\n",
    "def analyze_conversation(\n",
    "    messages: List[Dict[str, str]], \n",
    "    include_metadata: bool = True\n",
    ") -> Dict[str, Union[int, List[str]]]:\n",
    "    \"\"\"\n",
    "    Analyze a conversation for basic statistics.\n",
    "    \n",
    "    Args:\n",
    "        messages: List of message dictionaries with 'role' and 'content' keys\n",
    "        include_metadata: Whether to include additional metadata in results\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing conversation statistics\n",
    "        \n",
    "    Example:\n",
    "        >>> msgs = [{\"role\": \"user\", \"content\": \"Hello\"}, {\"role\": \"assistant\", \"content\": \"Hi there!\"}]\n",
    "        >>> analyze_conversation(msgs)\n",
    "        {'total_messages': 2, 'user_messages': 1, 'assistant_messages': 1, 'avg_length': 7.5}\n",
    "    \"\"\"\n",
    "    total = len(messages)\n",
    "    user_msgs = len([m for m in messages if m.get('role') == 'user'])\n",
    "    assistant_msgs = len([m for m in messages if m.get('role') == 'assistant'])\n",
    "    \n",
    "    total_chars = sum(len(m.get('content', '')) for m in messages)\n",
    "    avg_length = total_chars / total if total > 0 else 0\n",
    "    \n",
    "    result = {\n",
    "        'total_messages': total,\n",
    "        'user_messages': user_msgs,\n",
    "        'assistant_messages': assistant_msgs,\n",
    "        'average_length': round(avg_length, 2)\n",
    "    }\n",
    "    \n",
    "    if include_metadata:\n",
    "        result['roles'] = list(set(m.get('role', 'unknown') for m in messages))\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test the function\n",
    "sample_conversation = [\n",
    "    {\"role\": \"user\", \"content\": \"What is machine learning?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Machine learning is a subset of AI that enables computers to learn and improve from experience without being explicitly programmed.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you give me an example?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Sure! Email spam detection is a common example - the system learns to identify spam by analyzing thousands of emails.\"}\n",
    "]\n",
    "\n",
    "stats = analyze_conversation(sample_conversation)\n",
    "print(\"Conversation Analysis:\")\n",
    "for key, value in stats.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Show the power of type hints\n",
    "print(f\"\\nFunction signature: {analyze_conversation.__annotations__}\")\n",
    "print(f\"Function docstring available: {bool(analyze_conversation.__doc__)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_AAI",
   "language": "python",
   "name": "agentic_ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
